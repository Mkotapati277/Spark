package pack
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import scala.io.Source
import org.apache.spark.sql.types.{HIVE_TYPE_STRING, IntegerType}
import org.apache.spark.sql.{Row, SparkSession}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions
import org.apache.spark.sql.expressions
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions.{coalesce, col, count, dense_rank, exp, expr, monotonically_increasing_id, row_number, sum, to_date, window}
import org.apache.spark.sql.functions._

object Secanriospratice {
  def main(Args:Array[String]):Unit= {
    println("======Hello=======")
    val conf = new SparkConf().setAppName("first").setMaster("local[*]")
      .set("spark.driver.host", "localhost")
      .set("spark.driver.allowMultipleContexts", "true")
    val sc = new SparkContext(conf)
    sc.setLogLevel("ERROR")
    val spark = SparkSession.builder.getOrCreate()
    import spark.implicits._
    // Sample data
    val data = Seq(
      ("A", "D", "D"),
      ("B", "A", "A"),
      ("A", "D", "A") )
    // Create DataFrame
    val df = spark.createDataFrame(data).toDF("TeamA", "TeamB", "won")
    df.show()
    val wins = df.groupBy("won").count()
      .withColumnRenamed("won","TeamName")
      .withColumnRenamed("count","won")
    wins.show()
    // Calculate Total Games
    val TeamA = df.groupBy("TeamA").count()
      .withColumnRenamed("TeamA","TeamName")
      .withColumnRenamed("count","TotalA")
    TeamA.show()

    val TeamB = df.groupBy("TeamB").count()
      .withColumnRenamed("TeamB","TeamName")
      .withColumnRenamed("count","TotalB")
    TeamB.show()

    val TotalGames = TeamA.join(TeamB,Seq("TeamName"),"outer").na.fill(0)
      .withColumn("Total",col("TotalA")+ col("TotalB")).drop("TotalA","TotalB")
          TotalGames.show()
    val loses = TotalGames.join(wins,Seq("TeamName"),"left").na.fill(0)
      .withColumn("Lost",col("Total")-col("won")).select("TeamName","Lost","won")

    loses.show()
  }
}
