package pack
import org.apache.hadoop.hive.ql.exec.UDF
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import scala.io.Source
import org.apache.spark.sql.types.{HIVE_TYPE_STRING, IntegerType}
import org.apache.spark.sql.{Row, SparkSession, functions => F}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions
import org.apache.spark.sql.expressions
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.types.{StructType, StructField, IntegerType, StringType}
import org.apache.spark.sql.functions.{coalesce, col, count, dense_rank, exp, expr, monotonically_increasing_id, row_number, sum, to_date, window}
import org.apache.spark.sql.functions._
object Secanriospratice {
  def main(Args:Array[String]):Unit= {
    println("======Hello=======")
    val conf = new SparkConf().setAppName("first").setMaster("local[*]")
      .set("spark.driver.host", "localhost")
      .set("spark.driver.allowMultipleContexts", "true")
    val sc = new SparkContext(conf)
    sc.setLogLevel("ERROR")
    val spark = SparkSession.builder.getOrCreate()
    import spark.implicits._
    // Define the schema for the DataFrame
    val schema = StructType(List(
      StructField("id", IntegerType, nullable = false),
      StructField("name", StringType, nullable = false),
      StructField("salary", IntegerType, nullable = false),
      StructField("manager_id", IntegerType, nullable = true)))
    // Create the employee data
    val employeeData = Seq(
      Row(1, "John Smith", 10000, 3),
      Row(2, "Jane Anderson", 12000, 3),
      Row(3, "Tom Lanon", 15000, 4),
      Row(4, "Anne Connor", 20000, null),
      Row(5, "Jeremy York", 9000, 1))
    // Create the DataFrame
    val edf = spark.createDataFrame(spark.sparkContext.parallelize(employeeData),schema)
    // Show the DataFrame
    edf.show()
    val res = edf.as("e1").join(edf.as("m1"), $"e1.manager_id" === $"m1.id","left").orderBy("e1.id").select($"e1.id",$"e1.name",$"e1.salary",$"e1.manager_id",$"m1.name".as("manager_name"))
res.show()
  }
}
