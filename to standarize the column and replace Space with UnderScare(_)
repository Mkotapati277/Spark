import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName("StandardizeColumnNames")
  .getOrCreate()

// Load the CSV file into a DataFrame
val df = spark.read
  .option("header", "true") // Use the first row as header
  .csv("path/to/your/file.csv")

// Display the original DataFrame
println("Original DataFrame:")
df.show()

// Function to replace spaces with underscores in column names
def standardizeColumnNames(df: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame = {
  val newColumnNames = df.columns.map(_.replace(" ", "_")) // Replace spaces with underscores
  df.toDF(newColumnNames: _*) // Rename columns
}

// Apply the standardization function
val standardizedDF = standardizeColumnNames(df)

// Display the standardized DataFrame
println("Standardized DataFrame:")
standardizedDF.show()

// Optionally, save the standardized DataFrame to a new CSV file
// standardizedDF.write.option("header", "true").csv("path/to/save/standardized_file.csv")

// Stop the Spark session
spark.stop()
